@article{VAinstrument,
	author={Erin K. Nichols and Peter Byass and Daniel Chandramohan and Samuel J. Clark and Abraham D. Flaxman and Robert Jakob and Jordana Leitao and Nicolas Maire and Chalapati Rao and Ian Riley and Philip W. Setel},
	year={2018},
	month={Jan 10},
	title={The WHO 2016 verbal autopsy instrument: An international standard suitable for automated analysis by InterVA, InSilicoVA, and Tariff 2.0},
	journal={PLOS Medicine},
	volume={15},
	number={1},
	pages={e1-e1002486},
	abstract={Verbal autopsy (VA) is a practical method for determining probable causes of death at the population level in places where systems for medical certification of cause of death are weak. VA methods suitable for use in routine settings, such as civil registration and vital statistics (CRVS) systems, have developed rapidly in the last decade. These developments have been part of a growing global momentum to strengthen CRVS systems in low-income countries. With this momentum have come pressure for continued research and development of VA methods and the need for a single standard VA instrument on which multiple automated diagnostic methods can be developed. In 2016, partners harmonized a WHO VA standard instrument that fully incorporates the indicators necessary to run currently available automated diagnostic algorithms. The WHO 2016 VA instrument, together with validated approaches to analyzing VA data, offers countries solutions to improving information about patterns of cause-specific mortality. This VA instrument offers the opportunity to harmonize the automated diagnostic algorithms in the future. Despite all improvements in design and technology, VA is only recommended where medical certification of cause of death is not possible. The method can nevertheless provide sufficient information to guide public health priorities in communities in which physician certification of deaths is largely unavailable. The WHO 2016 VA instrument, together with validated approaches to analyzing VA data, offers countries solutions to improving information about patterns of cause-specific mortality.},
	isbn={1549-1676},
	url={https://www.ncbi.nlm.nih.gov/pubmed/29320495},
	doi={10.1371/journal.pmed.1002486},
	pmid={29320495}
}

@article{EAVA,
	author={Henry D. Kalter and Jamie Perin and Robert E. Black},
	year={2016},
	month={Jun 1},
	title={Validating hierarchical verbal autopsy expert algorithms in a large data set with known causes of death},
	journal={Journal of global health},
	volume={6},
	number={1},
	pages={010601},
	abstract={Physician assessment historically has been the most common method of analyzing verbal autopsy (VA) data. Recently, the World Health Organization endorsed two automated methods, Tariff 2.0 and InterVA-4, which promise greater objectivity and lower cost. A disadvantage of the Tariff method is that it requires a training data set from a prior validation study, while InterVA relies on clinically specified conditional probabilities. We undertook to validate the hierarchical expert algorithm analysis of VA data, an automated, intuitive, deterministic method that does not require a training data set. Using Population Health Metrics Research Consortium study hospital source data, we compared the primary causes of 1629 neonatal and 1456 1-59 month-old child deaths from VA expert algorithms arranged in a hierarchy to their reference standard causes. The expert algorithms were held constant, while five prior and one new "compromise" neonatal hierarchy, and three former child hierarchies were tested. For each comparison, the reference standard data were resampled 1000 times within the range of cause-specific mortality fractions (CSMF) for one of three approximated community scenarios in the 2013 WHO global causes of death, plus one random mortality cause proportions scenario. We utilized CSMF accuracy to assess overall population-level validity, and the absolute difference between VA and reference standard CSMFs to examine particular causes. Chance-corrected concordance (CCC) and Cohen's kappa were used to evaluate individual-level cause assignment. Overall CSMF accuracy for the best-performing expert algorithm hierarchy was 0.80 (range 0.57-0.96) for neonatal deaths and 0.76 (0.50-0.97) for child deaths. Performance for particular causes of death varied, with fairly flat estimated CSMF over a range of reference values for several causes. Performance at the individual diagnosis level was also less favorable than that for overall CSMF (neonatal: best CCC = 0.23, range 0.16-0.33; best kappa = 0.29, 0.23-0.35; child: best CCC = 0.40, 0.19-0.45; best kappa = 0.29, 0.07-0.35). Expert algorithms in a hierarchy offer an accessible, automated method for assigning VA causes of death. Overall population-level accuracy is similar to that of more complex machine learning methods, but without need for a training data set from a prior validation study.},
	isbn={2047-2978},
	doi={10.7189/jogh.06.010601},
	pmid={26953965}
}

@techreport{WHO2016,
	author={WHO},
	year={2016},
	title={Verbal autopsy standards: The 2016 WHO verbal autopsy instrument manual},
	url={https://www.who.int/publications/m/item/verbal-autopsy-standards-the-2016-who-verbal-autopsy-instrument}
}

@article{hierarchy,
	author={Daniel Chandramohan and Gillian H. Maude and Laura C. Rodrigues and Richard J. Hayes},
	year={1998},
	month={June},
	title={Verbal autopsies for adult deaths: their development and validation in a multicenter study},
	journal={Tropical Medicine and International Health},
	volume={3},
	number={6},
	doi={10.1046/j.1365-3156.1998.00255.x}
}

@article{PHMRC,
	author={Christopher JL Murray and Alan D. Lopez and Robert Black and Ramesh Ahuja and Said Mohd Ali and Abdullah Baqui and Lalit Dandona and Emily Dantzer and Vinita Das and Usha Dhingra and Arup Dutta and Wafaie Fawzi and Abraham D. Flaxman and Sara Gómez and Bernardo Hernández and Rohina Joshi and Henry Kalter and Aarti Kumar and Vishwajeet Kumar and Rafael Lozano and Marilla Lucero and Saurabh Mehta and Bruce Neal and Summer Lockett Ohno and Rajendra Prasad and Devarsetty Praveen and Zul Premji and Dolores Ramírez-Villalobos and Hazel Remolador and Ian Riley and Minerva Romero and Mwanaidi Said and Diozele Sanvictores and Sunil Sazawal and Veronica Tallo},
	year={2011},
	month={Aug 4},
	title={Population Health Metrics Research Consortium gold standard verbal autopsy validation study: design, implementation, and development of analysis datasets},
	journal={Population Health Metrics},
	volume={9},
	number={1},
	pages={27-27},
	abstract={Verbal autopsy methods are critically important for evaluating the leading causes of death in populations without adequate vital registration systems. With a myriad of analytical and data collection approaches, it is essential to create a high quality validation dataset from different populations to evaluate comparative method performance and make recommendations for future verbal autopsy implementation. This study was undertaken to compile a set of strictly defined gold standard deaths for which verbal autopsies were collected to validate the accuracy of different methods of verbal autopsy cause of death assignment. Data collection was implemented in six sites in four countries: Andhra Pradesh, India; Bohol, Philippines; Dar es Salaam, Tanzania; Mexico City, Mexico; Pemba Island, Tanzania; and Uttar Pradesh, India. The Population Health Metrics Research Consortium (PHMRC) developed stringent diagnostic criteria including laboratory, pathology, and medical imaging findings to identify gold standard deaths in health facilities as well as an enhanced verbal autopsy instrument based on World Health Organization (WHO) standards. A cause list was constructed based on the WHO Global Burden of Disease estimates of the leading causes of death, potential to identify unique signs and symptoms, and the likely existence of sufficient medical technology to ascertain gold standard cases. Blinded verbal autopsies were collected on all gold standard deaths. Over 12,000 verbal autopsies on deaths with gold standard diagnoses were collected (7,836 adults, 2,075 children, 1,629 neonates, and 1,002 stillbirths). Difficulties in finding sufficient cases to meet gold standard criteria as well as problems with misclassification for certain causes meant that the target list of causes for analysis was reduced to 34 for adults, 21 for children, and 10 for neonates, excluding stillbirths. To ensure strict independence for the validation of methods and assessment of comparative performance, 500 test-train datasets were created from the universe of cases, covering a range of cause-specific compositions. This unique, robust validation dataset will allow scholars to evaluate the performance of different verbal autopsy analytic methods as well as instrument design. This dataset can be used to inform the implementation of verbal autopsies to more reliably ascertain cause of death in national health information systems.},
	isbn={1478-7954},
	url={https://www.ncbi.nlm.nih.gov/pubmed/21816095},
	doi={10.1186/1478-7954-9-27},
	pmid={21816095}
}

@article{openVAtoolkit,
	author={Zehang Richard Li and Jason Thomas and Eungang Choi and Tyler H. McCormick and Samuel J Clark},
	year={2022},
	month={Dec 1},
	title={The openVA Toolkit for Verbal Autopsies},
	journal={The R journal},
	volume={14},
	number={4},
	pages={316-334},
	abstract={Verbal autopsy (VA) is a survey-based tool widely used to infer cause of death (COD) in regions without complete-coverage civil registration and vital statistics systems. In such settings, many deaths happen outside of medical facilities and are not officially documented by a medical professional. VA surveys, consisting of signs and symptoms reported by a person close to the decedent, are used to infer the COD for an individual, and to estimate and monitor the COD distribution in the population. Several classification algorithms have been developed and widely used to assign causes of death using VA data. However, the incompatibility between different idiosyncratic model implementations and required data structure makes it difficult to systematically apply and compare different methods. The openVA package provides the first standardized framework for analyzing VA data that is compatible with all openly available methods and data structure. It provides an open-source, R implementation of several most widely used VA methods. It supports different data input and output formats, and customizable information about the associations between causes and symptoms. The paper discusses the relevant algorithms, their implementations in R packages under the openVA suite, and demonstrates the pipeline of model fitting, summary, comparison, and visualization in the R environment.},
	isbn={2073-4859},
	url={https://www.ncbi.nlm.nih.gov/pubmed/37974934},
	doi={10.32614/RJ-2023-020},
	pmid={37974934}
}


@misc{openVA,
	author={Richard Li Zehang and Jason Thomas and Tyler H. McCormick and Samuel J. Clark},
	year={2024},
	title={openVA: Automated Method for Verbal Autopsy},
	journal={https://CRAN.R-project.org/package=openVA},
	keywords={Package Version 1.1.2}
}

@article{transfer,
	author={Abhirup Datta and Jacob Fiksel and Agbessi Amouzou and Scott L. Zeger},
	year={2021},
	month={Oct 13},
	title={Regularized Bayesian transfer learning for population-level etiological distributions},
	journal={Biostatistics (Oxford, England)},
	volume={22},
	number={4},
	pages={836-857},
	abstract={Computer-coded verbal autopsy (CCVA) algorithms predict cause of death from high-dimensional family questionnaire data (verbal autopsy) of a deceased individual, which are then aggregated to generate national and regional estimates of cause-specific mortality fractions. These estimates may be inaccurate if CCVA is trained on non-local training data different from the local population of interest. This problem is a special case of transfer learning, i.e., improving classification within a target domain (e.g., a particular population) with the classifier trained in a source-domain. Most transfer learning approaches concern individual-level (e.g., a person’s) classification. Social and health scientists such as epidemiologists are often more interested with understanding etiological distributions at the population-level. The sample sizes of their data sets are typically orders of magnitude smaller than those used for common transfer learning applications like image classification, document identification, etc. We present a parsimonious hierarchical Bayesian transfer learning framework to directly estimate population-level class probabilities in a target domain, using any baseline classifier trained on source-domain, and a small labeled target-domain dataset. To address small sample sizes, we introduce a novel shrinkage prior for the transfer error rates guaranteeing that, in absence of any labeled target-domain data or when the baseline classifier is perfectly accurate, our transfer learning agrees with direct aggregation of predictions from the baseline classifier, thereby subsuming the default practice as a special case. We then extend our approach to use an ensemble of baseline classifiers producing an unified estimate. Theoretical and empirical results demonstrate how the ensemble model favors the most accurate baseline classifier. We present data analyses demonstrating the utility of our approach.},
	isbn={1465-4644},
	url={https://www.ncbi.nlm.nih.gov/pubmed/32040180},
	doi={10.1093/biostatistics/kxaa001},
	pmid={32040180}
}

@article{datashift,
	author={Jacob Fiksel and Abhirup Datta and Agbessi Amouzou and Scott Zeger},
	year={2022},
	month={Oct 2},
	title={Generalized Bayes Quantification Learning under Dataset Shift},
	journal={Journal of the American Statistical Association},
	volume={117},
	number={540},
	pages={2163-2181},
	abstract={Quantification learning is the task of prevalence estimation for a test population using predictions from a classifier trained on a different population. Quantification methods assume that the sensitivities and specificities of the classifier are either perfect or transportable from the training to the test population. These assumptions are inappropriate in the presence of dataset shift, when the misclassification rates in the training population are not representative of those for the test population. Quantification under dataset shift has been addressed only for single-class (categorical) predictions and assuming perfect knowledge of the true labels on a small subset of the test population. We propose generalized Bayes quantification learning (GBQL) that uses the entire compositional predictions from probabilistic classifiers and allows for uncertainty in true class labels for the limited labeled test data. Instead of positing a full model, we use a model-free Bayesian estimating equation approach to compositional data using Kullback-Leibler loss-functions based only on a first-moment assumption. The idea will be useful in Bayesian compositional data analysis in general as it is robust to different generating mechanisms for compositional data and allows 0's and 1's in the compositional outputs thereby including categorical outputs as a special case. We show how our method yields existing quantification approaches as special cases. Extension to an ensemble GBQL that uses predictions from multiple classifiers yielding inference robust to inclusion of a poor classifier is discussed. We outline a fast and efficient Gibbs sampler using a rounding and coarsening approximation to the loss functions. We establish posterior consistency, asymptotic normality and valid coverage of interval estimates from GBQL, which to our knowledge are the first theoretical results for a quantification approach in the presence of local labeled data. We also establish finite sample posterior concentration rate. Empirical performance of GBQL is demonstrated through simulations and analysis of real data with evident dataset shift. Supplementary materials for this article are available online.},
	isbn={0162-1459},
	url={https://www.tandfonline.com/doi/abs/10.1080/01621459.2021.1909599},
	doi={10.1080/01621459.2021.1909599}
}

@article{singlecause,
	author={Jacob Fiksel and Brian Gilbert and Emily Wilson and Henry Kalter and Almamy Kante and Aveika Akum and Dianna Blau and Quique Bassat and Ivalda Macicame and Eduardo Samo Gudo and Robert Black and Scott Zeger and Agbessi Amouzou and Abhirup Datta},
	year={2023},
	month={May 2},
	title={Correcting for Verbal Autopsy Misclassification Bias in Cause-Specific Mortality Estimates},
	journal={The American journal of tropical medicine and hygiene},
	volume={108},
	number={5_Suppl},
	pages={66-77},
	abstract={Verbal autopsies (VAs) are extensively used to determine cause of death (COD) in many low- and middle-income countries. However, COD determination from VA can be inaccurate. Computer coded verbal autopsy (CCVA) algorithms used for this task are imperfect and misclassify COD for a large proportion of deaths. If not accounted for, this misclassification leads to biased estimates of cause-specific mortality fractions (CSMFs), a critical piece in health-policy making. Recent work has demonstrated that the knowledge of the CCVA misclassification rates can be used to calibrate raw VA-based CSMF estimates to account for the misclassification bias. In this manuscript, we review the current practices and issues with raw COD predictions from CCVA algorithms and provide a complete primer on how to use the VA calibration approach with the calibratedVA software to correct for verbal autopsy misclassification bias in cause-specific mortality estimates. We use calibratedVA to obtain CSMFs for child (1–59 months) and neonatal deaths using VA data from the Countrywide Mortality Surveillance for Action project in Mozambique.},
	isbn={0002-9637},
	url={https://www.ncbi.nlm.nih.gov/pubmed/37037438},
	doi={10.4269/ajtmh.22-0318},
	pmid={37037438}
}

@article{multicause,
	author={Brian Gilbert and Jacob Fiksel and Emily Wilson and Henry Kalter and Almamy Kante and Aveika Akum and Dianna Blau and Quique Bassat and Ivalda Macicame and Eduardo Samo Gudo and Robert Black and Scott Zeger and Agbessi Amouzou and Abhirup Datta},
	year={2023},
	month={May 2},
	title={Multi-Cause Calibration of Verbal Autopsy–Based Cause-Specific Mortality Estimates of Children and Neonates in Mozambique},
	journal={The American journal of tropical medicine and hygiene},
	volume={108},
	number={5_Suppl},
	pages={78-89},
	abstract={The Countrywide Mortality Surveillance for Action platform is collecting verbal autopsy (VA) records from a nationally representative sample in Mozambique. These records are used to estimate the national and subnational cause-specific mortality fractions (CSMFs) for children (1–59 months) and neonates (1–28 days). Cross-tabulation of VA-based cause-of-death (COD) determination against that from the minimally invasive tissue sampling (MITS) from the Child Health and Mortality Prevention project revealed important misclassification errors for all the VA algorithms, which if not accounted for will lead to bias in the estimates of CSMF from VA. A recently proposed Bayesian VA-calibration method is used that accounts for this misclassification bias and produces calibrated estimates of CSMF. Both the VA-COD and the MITS-COD can be multi-cause (i.e., suggest more than one probable COD for some of the records). To fully use this probabilistic COD data, we use the multi-cause VA calibration. Two different computer-coded VA algorithms are considered—InSilicoVA and EAVA—and the final CSMF estimates are obtained using an ensemble calibration that uses data from both the algorithms. The calibrated estimates consistently offer a better fit to the data and reveal important changes in the CSMF for both children and neonates in Mozambique after accounting for VA misclassification bias.},
	isbn={0002-9637},
	url={https://www.ncbi.nlm.nih.gov/pubmed/37037430},
	doi={10.4269/ajtmh.22-0319},
	pmid={37037430}
}

@article{heterogeneity,
	author={Sandipan Pramanik and Scott Zeger and Dianna Blau and Abhirup Datta},
	year={2023},
	month={Dec 5},
	title={Modeling Structure and Country-specific Heterogeneity in Misclassification Matrices of Verbal Autopsy-based Cause of Death Classifiers},
	abstract={Verbal autopsy (VA) algorithms are routinely used to determine individual-level causes of death (COD) in many low-and-middle-income countries, which are then aggregated to derive population-level cause-specific mortality fractions (CSMF), essential to informing public health policies. However, VA algorithms frequently misclassify COD and introduce bias in CSMF estimates. A recent method, VA-calibration, can correct for this bias using a VA misclassification matrix estimated from paired data on COD from both VA and minimally invasive tissue sampling (MITS) from the Child Health and Mortality Prevention Surveillance (CHAMPS) Network. Due to the limited sample size, CHAMPS data are pooled across all countries, implicitly assuming that the misclassification rates are homogeneous. In this research, we show that the VA misclassification matrices are substantially heterogeneous across countries, thereby biasing the VA-calibration. We develop a coherent framework for modeling country-specific misclassification matrices in data-scarce settings. We first introduce a novel base model based on two latent mechanisms: intrinsic accuracy and systematic preference to parsimoniously characterize misclassifications. We prove that they are identifiable from the data and manifest as a form of invariance in certain misclassification odds, a pattern evident in the CHAMPS data. Then we expand from this base model, adding higher complexity and country-specific heterogeneity via interpretable effect sizes. Shrinkage priors balance the bias-variance tradeoff by adaptively favoring simpler models. We publish uncertainty-quantified estimates of VA misclassification rates for 6 countries. This effort broadens VA-calibration's future applicability and strengthens ongoing efforts of using VA for mortality surveillance.},
	url={https://arxiv.org/abs/2312.03192},
	doi={10.48550/arxiv.2312.03192}
}


@article{countrywide,
	author={Ivalda Macicame and Almamy M. Kante and Emily Wilson and Brian Gilbert and Alain Koffi and Sheila Nhachungue and Celso Monjane and Pedro Duce and Antonio Adriano and Sergio Chicumbe and Ilesh Jani and Henry D. Kalter and Abhirup Datta and Scott Zeger and Robert E. Black and Eduardo Samo Gudo and Agbessi Amouzou and _. _},
	year={2023},
	month={May 2},
	title={Countrywide Mortality Surveillance for Action in Mozambique: Results from a National Sample-Based Vital Statistics System for Mortality and Cause of Death},
	journal={The American journal of tropical medicine and hygiene},
	volume={108},
	number={5_Suppl},
	pages={5-16},
	abstract={Sub-Saharan Africa lacks timely, reliable, and accurate national data on mortality and causes of death (CODs). In 2018 Mozambique launched a sample registration system (Countrywide Mortality Surveillance for Action [COMSA]-Mozambique), which collects continuous birth, death, and COD data from 700 randomly selected clusters, a nationally representative population of 828,663 persons. Verbal and social autopsy interviews are conducted for COD determination. We analyzed data collected in 2019–2020 to report mortality rates and cause-specific fractions. Cause-specific results were generated using computer-coded verbal autopsy (CCVA) algorithms for deaths among those age 5 years and older. For under-five deaths, the accuracy of CCVA results was increased through calibration with data from minimally invasive tissue sampling. Neonatal and under-five mortality rates were, respectively, 23 (95% CI: 18–28) and 80 (95% CI: 69–91) deaths per 1,000 live births. Mortality rates per 1,000 were 18 (95% CI: 14–21) among age 5–14 years, 26 (95% CI: 20–31) among age 15–24 years, 258 (95% CI: 230–287) among age 25–59 years, and 531 (95% CI: 490–572) among age 60+ years. Urban areas had lower mortality rates than rural areas among children under 15 but not among adults. Deaths due to infections were substantial across all ages. Other predominant causes by age group were prematurity and intrapartum-related events among neonates; diarrhea, malaria, and lower respiratory infections among children 1–59 months; injury, malaria, and diarrhea among children 5–14 years; HIV, injury, and cancer among those age 15–59 years; and cancer and cardiovascular disease at age 60+ years. The COMSA-Mozambique platform offers a rich and unique system for mortality and COD determination and monitoring and an opportunity to build a comprehensive surveillance system.},
	isbn={0002-9637},
	url={https://www.ncbi.nlm.nih.gov/pubmed/37037442},
	doi={10.4269/ajtmh.22-0367},
	pmid={37037442}
}

@misc{CrossVA,
	author={Jason Thomas and Eungang Choi and Zehang Li and Nicolas Marie and Tyler McCormick and Peter Byass and Samuel Clark},
	year={2021},
	title={CrossVA: Verbal Autopsy Data Transformation for InSilicoVA and InterVA5 Algorithms.},
	journal={https://CRAN.R-project.org/package=CrossVA},
	keywords={Package Version 1.0.0}
}

@misc{InterVA,
	author={Peter Byass},
	year={2020},
	title={InterVA},
	url={http://www.byass.uk/interva}
}

@misc{SmartVA,
	author={Abraham Flaxman},
	year={2025},
	title={SmartVA-Analyze},
	url={https://github.com/ihmeuw/SmartVA-Analyze/releases/tag/v3.0.0}
}


@misc{EAVAR,
	author={Emily B. Wilson and Henry Kalter and Abhi Datta and Sandipan Pramanik and Robert E. Black},
	year={2025},
	title={EAVA: Deterministic Verbal Autopsy Coding with Expert Algorithm Verbal Autopsy},
	journal={https://CRAN.R-project.org/package=EAVA}
}





